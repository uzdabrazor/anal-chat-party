#!/usr/bin/env python3
"""
Offline RAG with Ollama
"""

from __future__ import annotations

import argparse
import signal
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Optional

# Load environment variables from .env file
try:
    from dotenv import load_dotenv

    load_dotenv()
except ImportError:
    pass  # python-dotenv not installed, skip loading

from rich.console import Console
from rich.table import Table

from rag import build_or_load


@dataclass
class Args:
    rag_dir: Optional[str] = None
    model: str = "dolphin-mistral:7b"
    embed_model: str = "nomic-embed-text:v1.5"
    ollama_url: str = "http://localhost:11434"
    max_ctx_docs: int = 1
    chunks: int = 4
    context_size: int = 4096
    embed_batch_size: int = 32
    debug: bool = False
    rebuild: bool = False
    no_web: bool = False
    no_cli: bool = False
    system_prompt: Optional[str] = None
    name: Optional[str] = None
    listen: str = "localhost:8000"


console = Console()

signal.signal(signal.SIGINT, lambda *_: sys.exit(0))  # type: ignore

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def print_banner():
    """Print a compact banner"""
    banner = (
        "[bold magenta]â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[/]\n"
        "[bold magenta]â•‘[/]      [bold cyan]OLLAMA[/] [bold red]â€¢[/] "
        "[bold yellow]CHAT[/] [bold red]â€¢[/] [bold green]PARTY[/]      "
        "[bold magenta]â•‘[/]\n"
        "[bold magenta]â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[/]"
    )

    console.print(banner)
    console.print()


def main():
    print_banner()

    ap = argparse.ArgumentParser(
        description="Chat with Ollama, optionally with RAG using local documents"
    )
    ap.add_argument("--rag-dir", help="Directory with documents for RAG (optional)")
    ap.add_argument(
        "--model", default="dolphin-mistral:7b", help="LLM to use for chat responses"
    )
    ap.add_argument(
        "--embed-model",
        default="nomic-embed-text:v1.5",
        help="Embedding model for document vectorization",
    )
    ap.add_argument(
        "--ollama-url", default="http://localhost:11434", help="Ollama server URL"
    )
    ap.add_argument(
        "--max-ctx-docs",
        type=int,
        default=1,
        help="Maximum documents to include in context",
    )
    ap.add_argument("--chunks", type=int, default=4, help="Maximum chunks per query")
    ap.add_argument(
        "--context-size",
        type=int,
        default=4096,
        help="LLM context window size in tokens",
    )
    ap.add_argument(
        "--embed-batch-size",
        type=int,
        default=32,
        help="Batch size for embedding generation",
    )
    ap.add_argument(
        "--debug", action="store_true", help="Enable debug output and detailed logging"
    )
    ap.add_argument(
        "--rebuild", action="store_true", help="Force rebuild of document index"
    )
    ap.add_argument(
        "--no-web", action="store_true", help="Disable web interface (CLI only)"
    )
    ap.add_argument(
        "--no-cli", action="store_true", help="Disable CLI interface (Web only, for systemd services)"
    )
    ap.add_argument(
        "--system-prompt",
        help="Custom system prompt for the LLM",
    )
    ap.add_argument(
        "--system-prompt-file",
        help="Path to file containing custom system prompt",
    )
    ap.add_argument(
        "--name",
        help="Your name (will be included in context messages)",
    )
    ap.add_argument(
        "--listen",
        default="localhost:8000",
        help="Listen address and port in format host:port (default: localhost:8000)",
    )
    parsed_args = ap.parse_args()

    # Validate conflicting options
    if parsed_args.no_web and parsed_args.no_cli:
        console.print("[bold red]Error: Cannot use both --no-web and --no-cli (nothing would run!)[/]")
        sys.exit(1)

    # Handle system prompt from file
    system_prompt_value = parsed_args.system_prompt
    if parsed_args.system_prompt_file:
        if parsed_args.system_prompt:
            console.print("[bold red]Error: Cannot use both --system-prompt and --system-prompt-file[/]")
            sys.exit(1)
        try:
            with open(parsed_args.system_prompt_file, 'r', encoding='utf-8') as f:
                system_prompt_value = f.read().strip()
        except FileNotFoundError:
            console.print(f"[bold red]Error: System prompt file not found: {parsed_args.system_prompt_file}[/]")
            sys.exit(1)
        except Exception as e:
            console.print(f"[bold red]Error reading system prompt file: {e}[/]")
            sys.exit(1)

    args = Args(
        rag_dir=parsed_args.rag_dir,
        model=parsed_args.model,
        embed_model=parsed_args.embed_model,
        ollama_url=parsed_args.ollama_url,
        max_ctx_docs=parsed_args.max_ctx_docs,
        chunks=parsed_args.chunks,
        context_size=parsed_args.context_size,
        embed_batch_size=parsed_args.embed_batch_size,
        debug=parsed_args.debug,
        rebuild=parsed_args.rebuild,
        no_web=parsed_args.no_web,
        no_cli=parsed_args.no_cli,
        system_prompt=system_prompt_value,
        name=parsed_args.name,
        listen=parsed_args.listen,
    )

    # Show all settings in debug mode
    if args.debug:
        settings_table = Table(
            title="ğŸ”§ Configuration Settings",
            show_header=True,
            header_style="bold magenta",
        )
        settings_table.add_column("Setting", style="cyan", width=20)
        settings_table.add_column("Value", style="green")

        settings_table.add_row(
            "ğŸ“ RAG directory",
            str(args.rag_dir) if args.rag_dir else "None (RAG disabled)",
        )
        settings_table.add_row("ğŸ¤– LLM name", args.model)
        settings_table.add_row("ğŸ”® Embedding model", args.embed_model)
        settings_table.add_row("ğŸŒ Ollama URL", args.ollama_url)
        settings_table.add_row("ğŸ“„ Max context docs", str(args.max_ctx_docs))
        settings_table.add_row("ğŸ“¦ Max chunks", str(args.chunks))
        settings_table.add_row("ğŸ§  Context size", f"{args.context_size:,} tokens")
        settings_table.add_row("âš¡ Embed batch size", str(args.embed_batch_size))
        settings_table.add_row("ğŸ”„ Rebuild index", "Yes" if args.rebuild else "No")
        settings_table.add_row(
            "ğŸŒ Web interface", "Disabled" if args.no_web else "Enabled"
        )
        system_prompt_display = (
            "Custom" if args.system_prompt else "Default (Cyberpunk)"
        )
        settings_table.add_row("ğŸ’¬ System prompt", system_prompt_display)
        user_name_display = args.name if args.name else "Anonymous"
        settings_table.add_row("ğŸ‘¤ User name", user_name_display)
        settings_table.add_row("ğŸ› Debug mode", "Enabled")

        console.print(settings_table)
        console.print()

    # Build or load index only if RAG directory is provided
    if args.rag_dir:
        # Validate RAG directory exists first
        rag_path = Path(args.rag_dir).expanduser()
        if not rag_path.exists():
            console.print(f"[bold red]Error: RAG directory does not exist: {args.rag_dir}[/]")
            sys.exit(1)
        if not rag_path.is_dir():
            console.print(f"[bold red]Error: RAG path is not a directory: {args.rag_dir}[/]")
            sys.exit(1)

        try:
            index, store = build_or_load(
                rag_path,
                args.embed_model,
                args.ollama_url,
                args.rebuild,
                args.debug,
                args.embed_batch_size,
            )
            # If no documents found, switch to non-RAG mode
            if index is None:
                console.print(
                    "[yellow]ğŸ“„ Switching to non-RAG mode due to no documents found.[/]"
                )
                index, store = None, {}
        except RuntimeError as e:
            console.print(f"[bold red]Error: {e}[/]")
            sys.exit(1)
    else:
        # No RAG directory provided, disable RAG functionality
        index, store = None, None
        if args.debug:
            console.print(
                "[yellow]âš ï¸  No RAG directory provided. RAG functionality disabled.[/]"
            )

    # Import CLI and web components
    from shared_state import shared_state

    # Start web server if enabled
    web_enabled = not args.no_web
    if web_enabled:
        from web_server import run_web_server

        # Parse listen address
        host, port = args.listen.split(":")
        port = int(port)

        # Start web server in background thread (silent startup)
        run_web_server(host=host, port=port)

    # Set RAG components in shared state (needed for both CLI and web-only mode)
    shared_state.set_rag_components(index, store or {}, args)

    # Initialize conversation with system message
    from chat import SYSTEM_PROMPT
    system_prompt = args.system_prompt if args.system_prompt else SYSTEM_PROMPT
    system_msg = {"role": "system", "content": system_prompt}
    shared_state.add_message(system_msg, source="internal")

    # Run CLI interface or just keep web server running
    if not args.no_cli:
        # Run CLI interface
        from cli_handler_simple import run_simple_cli_interface
        try:
            run_simple_cli_interface(args, index, store or {}, web_enabled)
        except KeyboardInterrupt:
            console.print("\n[bold red]ğŸ›‘ Shutting down gracefully...[/]")
            if web_enabled:
                shared_state.shutdown()
        except Exception as e:
            console.print(f"[bold red]Error: {e}[/]")
            if web_enabled:
                shared_state.shutdown()
    else:
        # Web-only mode: just keep the server running
        console.print("ğŸš€ [bold green]Starting ANAL CHAT PARTY (Web-only mode)...[/]")
        console.print(f"ğŸŒ [bold blue]Web interface available at http://{args.listen}[/]")
        console.print("ğŸ”„ [dim]Press Ctrl+C to stop the server[/]\n")

        try:
            # Keep the main thread alive
            import signal
            import time

            # Wait forever until interrupted
            while not shared_state.shutdown_event.is_set():
                time.sleep(1)
        except KeyboardInterrupt:
            console.print("\n[bold red]ğŸ›‘ Shutting down...[/]")
            shared_state.shutdown()


if __name__ == "__main__":
    main()
